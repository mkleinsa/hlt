% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hlt.R
\name{hlt}
\alias{hlt}
\title{Higher-Order Item Response Theory (Latent Trait Theory) with Regression}
\usage{
hlt(x, z = NULL, id, iter, burn = iter/2, delta, progress = TRUE)
}
\arguments{
\item{x}{matrix of item responses. Responses must be integers where the 
lowest value is 0 and the highest value is the maximum possible response
for the item with no gaps. If a question is asked with 5 possible responses,
then the possible values should be c(0,1,2,3,4,5). For binary items, use
c(0,1).}

\item{z}{centered numeric matrix of predictors for the latent regression. 
Default is `z = NULL` so that no regression is performed. All columns
of this matrix must be numeric. For binary items, use the values c(0,1).
For continuous items, center the values on the mean and divide by the 
standard deviation (normalized). For factors with more than two levels, 
recode into multiple columns of c(0,1).}

\item{id}{I.D. vector indexing first-order latent dimension membership
for each of the first-order latent dimensions. We index starting from zero,
not one. If there are three first-order .
latent dimensions with 5 questions per dimension, then the vector will look
like c(0,0,0,0,0,1,1,1,1,1,2,2,2,2,2).}

\item{iter}{number of total iterations.}

\item{burn}{number of burn in iterations.}

\item{delta}{tuning parameter for Metropolis-Hanstings algorithm. Alter 
delta until acceptance.ratio =~ 0.234.}

\item{progress}{boolean, show progress bar? Defaults to TRUE.}
}
\value{
A matrix of posterior estimates. Rows are the draws and columns
are the named parameters.
}
\description{
Fit a higher-order item response theory model under the generalized 
partial credit measurement model. The goal is to explain multiple latent dimensions
by a single higher-order dimension. We extend this model to perform regression 
on the general latent dimension.
}
\examples{

# Example 1: sumulated data
ntheta = 3
id = c(0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2)
lambda = c(0.8, 0.4, 0.3)
dL = 5

# small n test
set.seed(7794)
xdat = hltsim(n = 100, ntheta = ntheta, lambda = lambda, 
              tJ = id, dL = dL, mua = 1, mud = 1.4, siga = 0.8, sigd = 1)
x = xdat$x
mod = hlt(x, ntheta = 3, id = id, iter = 1000, delta = 0.03)
mod$accept.rate
post = mod$post

# increase n
set.seed(7794)
xdat = hltsim(n = 150, ntheta = ntheta, lambda = lambda, 
              tJ = id, dL = dL, mua = 1, mud = 1.4, siga = 0.8, sigd = 1,
              beta = 1)
x = xdat$x
mod = hlt(x, ntheta = 3, id = id, iter = 40000, burn = 30000, delta = 0.05)
mod$accept.rate
post = mod$post

# Regression example 
set.seed(2034)
nB = 1
n = 300
z = matrix(sample(0:1, n, replace = TRUE), nrow = n, ncol = nB)
xdat = hltsim(n = n, ntheta = 3, lambda = c(0.8, 0.4, 0.3), 
              tJ = id, dL = 4, mua = 1, mud = 1.4, siga = 0.8, sigd = 1,
              regression = TRUE, z = z, nB = nB, beta = 1)
apply(xdat$x, 2, table)
lm(xdat$theta[,4] ~ xdat$z)
xdat$s.beta
x = xdat$x
mod = hlt(x, z = z, id = id, iter = 1e5, delta = 0.017)
mod = hlt(x, z = z, id = id, iter = 1e6, burn = 9e5, delta = 0.017)
mod$accept.rate
post = mod$post
apply(post, 2, mean)

smy = function(x) {c(mean = mean(x), se = sd(x), quantile(x, probs = c(0.025, 0.5, 0.7, 0.975)))}
apply(post[, "beta1", drop = FALSE], 2, smy)

summary(mod, param = "beta")
summary(mod, param = "lambda")
summary(mod, param = "alpha")
summary(mod, param = "delta")
summary(mod, param = "theta", dimension = 1)
summary(mod, param = "theta", dimension = 2)
summary(mod, param = "theta", dimension = 3)
summary(mod, param = "theta", dimension = 4)

summary(mod, param = "cor.theta", cor.theta = c(1,2))

th = summary(mod, param = "theta", dimension = 1)
cor(th, xdat$theta[,1])

plot(mod, "lambda1")
plot(mod, "lambda2")
plot(mod, "lambda3")
plot(mod, "a1")
plot(mod, "mud")
plot(mod, "d2")
plot(mod, "beta1")
}
